{"version":3,"file":"lite-batcher.js","names":["fn: (items: Array<TValue>) => void","options: LiteBatcherOptions<TValue>"],"sources":["../src/lite-batcher.ts"],"sourcesContent":["/**\n * Options for configuring a lite batcher instance\n */\nexport interface LiteBatcherOptions<TValue> {\n  /**\n   * Custom function to determine if a batch should be processed\n   * Return true to process the batch immediately\n   */\n  getShouldExecute?: (\n    items: Array<TValue>,\n    batcher: LiteBatcher<TValue>,\n  ) => boolean\n  /**\n   * Maximum number of items in a batch\n   * @default Infinity\n   */\n  maxSize?: number\n  /**\n   * Callback fired after a batch is processed\n   */\n  onExecute?: (batch: Array<TValue>, batcher: LiteBatcher<TValue>) => void\n  /**\n   * Callback fired after items are added to the batcher\n   */\n  onItemsChange?: (batcher: LiteBatcher<TValue>) => void\n  /**\n   * Whether the batcher should start processing immediately\n   * @default true\n   */\n  started?: boolean\n  /**\n   * Maximum time in milliseconds to wait before processing a batch.\n   * If the wait duration has elapsed, the batch will be processed.\n   * If not provided, the batch will not be triggered by a timeout.\n   * @default Infinity\n   */\n  wait?: number | ((batcher: LiteBatcher<TValue>) => number)\n}\n\n/**\n * A lightweight class that collects items and processes them in batches.\n *\n * This is an alternative to the Batcher in the core @tanstack/pacer package, but is more\n * suitable for libraries and npm packages that need minimal overhead. Unlike the core Batcher,\n * this version does not use TanStack Store for state management, has no devtools integration,\n * no callbacks, and provides only essential batching functionality.\n *\n * Batching is a technique for grouping multiple operations together to be processed as a single unit.\n * This synchronous version is lighter weight and often all you need.\n *\n * The Batcher provides a flexible way to implement batching with configurable:\n * - Maximum batch size (number of items per batch)\n * - Time-based batching (process after X milliseconds)\n * - Custom batch processing logic via getShouldExecute\n *\n * Features included:\n * - Core batching functionality (addItem, flush, clear, cancel)\n * - Size-based batching (maxSize)\n * - Time-based batching (wait timeout)\n * - Custom condition batching (getShouldExecute)\n * - Manual processing controls\n * - Public mutable options\n * - Callback support for monitoring batch execution and state changes\n *\n * Features NOT included (compared to core Batcher):\n * - No TanStack Store state management\n * - No devtools integration\n * - No complex state tracking (execution counts, etc.)\n * - No reactive state management\n *\n * @example\n * ```ts\n * // Basic batching\n * const batcher = new LiteBatcher<number>(\n *   (items) => console.log('Processing batch:', items),\n *   {\n *     maxSize: 5,\n *     wait: 2000,\n *     onExecute: (batch, batcher) => {\n *       console.log('Batch executed with', batch.length, 'items');\n *     },\n *     onItemsChange: (batcher) => {\n *       console.log('Batch size changed to:', batcher.size);\n *     }\n *   }\n * );\n *\n * batcher.addItem(1);\n * batcher.addItem(2);\n * // After 2 seconds or when 5 items are added, whichever comes first,\n * // the batch will be processed\n * ```\n *\n * @example\n * ```ts\n * // Custom condition batching\n * const batcher = new LiteBatcher<Task>(\n *   (items) => processTasks(items),\n *   {\n *     getShouldExecute: (items) => items.some(task => task.urgent),\n *     maxSize: 10,\n *   }\n * );\n *\n * batcher.addItem({ name: 'normal', urgent: false });\n * batcher.addItem({ name: 'urgent', urgent: true }); // Triggers immediate processing\n * ```\n */\nexport class LiteBatcher<TValue> {\n  private items: Array<TValue> = []\n  private timeoutId: NodeJS.Timeout | null = null\n  private _isPending = false\n\n  constructor(\n    public fn: (items: Array<TValue>) => void,\n    public options: LiteBatcherOptions<TValue> = {},\n  ) {\n    // Set defaults\n    this.options.maxSize = this.options.maxSize ?? Infinity\n    this.options.started = this.options.started ?? true\n    this.options.wait = this.options.wait ?? Infinity\n    this.options.getShouldExecute =\n      this.options.getShouldExecute ?? (() => false)\n  }\n\n  /**\n   * Number of items currently in the batch\n   */\n  get size(): number {\n    return this.items.length\n  }\n\n  /**\n   * Whether the batch has no items to process (items array is empty)\n   */\n  get isEmpty(): boolean {\n    return this.items.length === 0\n  }\n\n  /**\n   * Whether the batcher is waiting for the timeout to trigger batch processing\n   */\n  get isPending(): boolean {\n    return this._isPending\n  }\n\n  private getWait(): number {\n    if (typeof this.options.wait === 'function') {\n      return this.options.wait(this)\n    }\n    return this.options.wait!\n  }\n\n  /**\n   * Adds an item to the batcher\n   * If the batch size is reached, timeout occurs, or getShouldExecute returns true, the batch will be processed\n   */\n  addItem = (item: TValue): void => {\n    this.items.push(item)\n    this._isPending = this.options.wait !== Infinity\n    this.options.onItemsChange?.(this)\n\n    const shouldProcess =\n      this.items.length >= this.options.maxSize! ||\n      this.options.getShouldExecute!(this.items, this)\n\n    if (shouldProcess) {\n      this.execute()\n    } else if (this.options.wait !== Infinity) {\n      this.clearTimeout() // clear any pending timeout to replace it with a new one\n      this.timeoutId = setTimeout(() => this.execute(), this.getWait())\n    }\n  }\n\n  /**\n   * Processes the current batch of items.\n   * This method will automatically be triggered if the batcher is running and any of these conditions are met:\n   * - The number of items reaches maxSize\n   * - The wait duration has elapsed\n   * - The getShouldExecute function returns true upon adding an item\n   *\n   * You can also call this method manually to process the current batch at any time.\n   */\n  private execute = (): void => {\n    if (this.items.length === 0) {\n      return\n    }\n\n    const batch = this.peekAllItems() // copy of the items to be processed (to prevent race conditions)\n    this.clear() // Clear items before processing to prevent race conditions\n\n    this.fn(batch) // EXECUTE\n    this.options.onExecute?.(batch, this)\n  }\n\n  /**\n   * Processes the current batch of items immediately\n   */\n  flush = (): void => {\n    this.clearTimeout() // clear any pending timeout\n    this.execute() // execute immediately\n  }\n\n  /**\n   * Returns a copy of all items in the batcher\n   */\n  peekAllItems = (): Array<TValue> => {\n    return [...this.items]\n  }\n\n  private clearTimeout = (): void => {\n    if (this.timeoutId) {\n      clearTimeout(this.timeoutId)\n      this.timeoutId = null\n    }\n  }\n\n  /**\n   * Removes all items from the batcher\n   */\n  clear = (): void => {\n    const hadItems = this.items.length > 0\n    this.items = []\n    this._isPending = false\n    if (hadItems) {\n      this.options.onItemsChange?.(this)\n    }\n  }\n\n  /**\n   * Cancels any pending execution that was scheduled.\n   * Does NOT clear out the items.\n   */\n  cancel = (): void => {\n    this.clearTimeout()\n    this._isPending = false\n  }\n}\n\n/**\n * Creates a batcher that processes items in batches.\n *\n * This is an alternative to the batch function in the core @tanstack/pacer package, but is more\n * suitable for libraries and npm packages that need minimal overhead. Unlike the core version,\n * this function creates a batcher with no external dependencies, devtools integration, or reactive state.\n *\n * @example\n * ```ts\n * const batchItems = liteBatch<number>(\n *   (items) => console.log('Processing:', items),\n *   {\n *     maxSize: 3,\n *   }\n * );\n *\n * batchItems(1);\n * batchItems(2);\n * batchItems(3); // Triggers batch processing\n * ```\n */\nexport function liteBatch<TValue>(\n  fn: (items: Array<TValue>) => void,\n  options: LiteBatcherOptions<TValue> = {},\n): (item: TValue) => void {\n  const batcher = new LiteBatcher<TValue>(fn, options)\n  return batcher.addItem\n}\n"],"mappings":";;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;AA4GA,IAAa,cAAb,MAAiC;CAK/B,YACE,AAAOA,IACP,AAAOC,UAAsC,EAAE,EAC/C;EAFO;EACA;eANsB,EAAE;mBACU;oBACtB;kBA8CV,SAAuB;AAChC,QAAK,MAAM,KAAK,KAAK;AACrB,QAAK,aAAa,KAAK,QAAQ,SAAS;AACxC,QAAK,QAAQ,gBAAgB,KAAK;AAMlC,OAHE,KAAK,MAAM,UAAU,KAAK,QAAQ,WAClC,KAAK,QAAQ,iBAAkB,KAAK,OAAO,KAAK,CAGhD,MAAK,SAAS;YACL,KAAK,QAAQ,SAAS,UAAU;AACzC,SAAK,cAAc;AACnB,SAAK,YAAY,iBAAiB,KAAK,SAAS,EAAE,KAAK,SAAS,CAAC;;;uBAavC;AAC5B,OAAI,KAAK,MAAM,WAAW,EACxB;GAGF,MAAM,QAAQ,KAAK,cAAc;AACjC,QAAK,OAAO;AAEZ,QAAK,GAAG,MAAM;AACd,QAAK,QAAQ,YAAY,OAAO,KAAK;;qBAMnB;AAClB,QAAK,cAAc;AACnB,QAAK,SAAS;;4BAMoB;AAClC,UAAO,CAAC,GAAG,KAAK,MAAM;;4BAGW;AACjC,OAAI,KAAK,WAAW;AAClB,iBAAa,KAAK,UAAU;AAC5B,SAAK,YAAY;;;qBAOD;GAClB,MAAM,WAAW,KAAK,MAAM,SAAS;AACrC,QAAK,QAAQ,EAAE;AACf,QAAK,aAAa;AAClB,OAAI,SACF,MAAK,QAAQ,gBAAgB,KAAK;;sBAQjB;AACnB,QAAK,cAAc;AACnB,QAAK,aAAa;;AArHlB,OAAK,QAAQ,UAAU,KAAK,QAAQ,WAAW;AAC/C,OAAK,QAAQ,UAAU,KAAK,QAAQ,WAAW;AAC/C,OAAK,QAAQ,OAAO,KAAK,QAAQ,QAAQ;AACzC,OAAK,QAAQ,mBACX,KAAK,QAAQ,2BAA2B;;;;;CAM5C,IAAI,OAAe;AACjB,SAAO,KAAK,MAAM;;;;;CAMpB,IAAI,UAAmB;AACrB,SAAO,KAAK,MAAM,WAAW;;;;;CAM/B,IAAI,YAAqB;AACvB,SAAO,KAAK;;CAGd,AAAQ,UAAkB;AACxB,MAAI,OAAO,KAAK,QAAQ,SAAS,WAC/B,QAAO,KAAK,QAAQ,KAAK,KAAK;AAEhC,SAAO,KAAK,QAAQ;;;;;;;;;;;;;;;;;;;;;;;;AA8GxB,SAAgB,UACd,IACA,UAAsC,EAAE,EAChB;AAExB,QADgB,IAAI,YAAoB,IAAI,QAAQ,CACrC"}